# Local LLM Configuration
# No API keys needed! This project uses local LLM (Ollama) for distractor generation.
#
# To setup:
# 1. Install Ollama from https://ollama.ai/
# 2. Download a model: ollama pull llama3.2
# 3. Run the quiz setup: python setup_questions.py your_questions.csv